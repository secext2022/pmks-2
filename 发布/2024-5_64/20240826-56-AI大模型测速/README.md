# 20240826-56

标题:
**本地运行 AI 有多慢 ? 大模型推理测速 (llama.cpp, Intel GPU A770)**

索引: `穷人实验室`

关键词: llama.cpp, AI, A770, vulkan, SYCL, GNU/Linux, 测速


## 图文版

[已发布](./a.md): (5)

知乎 单篇限制最大 10 万字:

+ <https://zhuanlan.zhihu.com/p/716471820>
+ <https://zhuanlan.zhihu.com/p/716473539>
+ <https://zhuanlan.zhihu.com/p/716473613>

掘金:

+ <https://juejin.cn/post/7407004271328002100>
+ <https://juejin.cn/post/7406697002539778088>
+ <https://juejin.cn/post/7406697002539794472>

CSDN:

+ <https://blog.csdn.net/secext2022/article/details/141563659>
+ <https://blog.csdn.net/secext2022/article/details/141563727>

微信公众号 (markdown):

+ <https://mp.weixin.qq.com/s?__biz=MzkyMDU4ODYwMQ==&mid=2247484233&idx=1&sn=377f42ea954c5482f71729e17e0ddd55&chksm=c191db1ff6e65209f4d86a751f371d5e14dba280e4335d8d724d364b3adeb28fe598ea098d16&token=669524010&lang=zh_CN#rd>

----

本文使用 **微信 Markdown 编辑器** 格式化发布: <https://github.com/doocs/md>

----

首发日期 `2024-08-26`, 以下为原文内容:

----

本文使用 **Bilibili-Markdown** 工具进行格式化排版:
<https://www.bilibili.com/read/cv18986956/>

+ <https://www.bilibili.com/read/cv39123967/>
